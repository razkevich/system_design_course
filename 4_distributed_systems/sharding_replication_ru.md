# Шардинг против репликации: ментальная модель, которую вы действительно поймете

Шардинг и репликация — два фундаментальных подхода к построению распределенных систем, но разница между ними и их компромиссы не всегда очевидны на практике.

## Система с одним экземпляром

![[sharding_replication_1.png]]

Это самая простая конфигурация, где все происходит внутри одного узла. Хотя она не предлагает горизонтальной масштабируемости, она обеспечивает сильные гарантии согласованности и простое рассуждение о состоянии системы. Примеры включают PostgreSQL с одним экземпляром, Redis без кластеризации или автономные серверы приложений. Единственный способ справиться с возросшей нагрузкой — это вертикальное масштабирование (добавление большего количества CPU, памяти или хранилища к той же машине), которое имеет физические и экономические ограничения. В конечном итоге вы столкнетесь с аппаратными ограничениями, которые сделают дальнейшее масштабирование невозможным или экономически нецелесообразным.

## Репликация с одним лидером

![[sharding_replication_2.png]]

Самая простая форма введения масштабирования в такую систему — добавление большего количества фолловер-реплик. Эти реплики могут быть либо read-репликами для обслуживания клиентских запросов на чтение, либо просто находиться в горячем резерве, чтобы заменить лидера (который также называется мастером или write-репликой) в случае, если он выйдет из строя или сломается. Все реплики имеют доступ к полному набору данных (в базах данных обычно данные полностью реплицируются), поэтому нет необходимости вводить маршрутизацию трафика или стратегии шардинга (кроме маршрутизации записей всегда к лидеру).

В обоих случаях лидер должен реплицировать свои данные на эти реплики, и есть различные подходы к этому (например, в базах данных — отправка журнала опережающей записи, WAL, или логических команд). Но у нас все еще есть только один лидер для обработки запросов, которые изменяют данные или состояние.

Поэтому клиенты должны подключаться только к лидеру для выполнения write-запросов, но read-запросы могут обслуживаться любой read-репликой. Это смягчает сценарии использования с высоким соотношением чтения к записи, но не очень помогает, когда у нас много записей. На самом деле, для некоторых сценариев с высокой интенсивностью записи это может быть не лучшей конфигурацией, потому что:
* если мы выбираем синхронный режим репликации, то наша система может стать медленной или даже недоступной в случае, если она не может достичь некоторых read-реплик
* если мы выбираем асинхронный режим репликации, то читатели могут видеть устаревшие данные, если они обращаются к read-репликам, что может быть неприемлемо (например, подумайте об использовании устаревших/несогласованных данных банковского счета)

Еще один вопрос — что происходит, если лидер умирает. Обычно есть два подхода:
* ручное переключение — администратор должен прийти и установить одну из read-реплик в качестве нового лидера. Некоторые традиционные настройки баз данных все еще используют этот подход для критических систем, где администраторы хотят полного контроля над решениями о переключении. Система становится недоступной до вмешательства администратора, но преимущество в том, что вы избегаете сценариев split-brain и обеспечиваете, чтобы наиболее квалифицированная реплика стала новым лидером на основе человеческого суждения.
* автоматическое назначение лидера — системы используют алгоритм распределенного консенсуса, такой как Paxos или Raft или другие, для выбора нового лидера. Преимущество — более быстрое восстановление и уменьшенное человеческое вмешательство, но недостаток — сложность и потенциал для сценариев split-brain, если алгоритм консенсуса терпит неудачу или происходят сетевые разделения.

Один яркий пример, поддерживающий этот подход, — PostgreSQL с потоковой репликацией. Вы можете настроить hot standby реплики и read-реплики, выбирая между синхронными и асинхронными режимами репликации. Другие примеры включают MySQL с master-slave репликацией, MongoDB replica sets (до шардинга) и Redis Sentinel для высокой доступности.

Помимо некоторых ограничений масштабируемости, которые мы обсуждали, на самом деле есть одно важное преимущество этого подхода: естественная линеаризуемость. Если все записи проходят через одного и того же лидера, легко обеспечить глобальный порядок, также легко рассуждать об этом.

## Репликация с несколькими лидерами

![[sharding_replication_3.png]]

Некоторые ситуации, такие как гео-распределенные развертывания, совместное редактирование (ваше мобильное устройство, которое может быть оффлайн в течение дней, и сервер — тоже распределенная система!) или требования высокой доступности, требуют настройки нескольких реплик и назначения более одной из них в качестве write-реплик (то есть лидеров). Другими словами, у нас есть несколько экземпляров, которые могут принимать записи одновременно.

В этой настройке каждый лидер действует как фолловер для других лидеров. Также каждый лидер обычно управляет своим собственным набором фолловеров. Лидеры могут иметь разные топологии для распространения изменений: все-ко-всем (каждый лидер реплицирует на каждого другого лидера, используется в небольших кластерах), кольцевая (изменения перетекают в кольце, более эффективна по пропускной способности, но с большей задержкой) и звездообразная (один центральный лидер координирует с другими, проще, но создает узкое место).

В отличие от систем с одним лидером, настройки с несколькими лидерами жертвуют естественным упорядочиванием записей, делая разрешение конфликтов необходимым. Однако они наследуют преимущества масштабирования чтения от систем с одним лидером, добавляя при этом возможности масштабирования записи. Компромисс — увеличенная сложность в поддержании согласованности между несколькими write-узлами.

### Разрешение конфликтов

Если записи в одну точку данных приходят к разным репликам, и все они пытаются реплицировать это изменение, мы получим конфликт, потому что у нас есть два конфликтующих значения для одной и той же точки данных. Есть набор известных подходов к разрешению конфликтов:
* LWW - последняя запись побеждает — самый жестокий, он просто берет версию, которую считает самой последней. Этот подход проблематичен из-за расхождения часов между разными машинами — даже с синхронизацией NTP часы могут дрейфовать, приводя к неправильным решениям об упорядочивании и потенциальной потере данных, когда «неправильная» запись считается более недавней.
* Векторы версий: отслеживание причинности между обновлениями
* Разрешение, специфичное для приложения: позволить коду приложения обрабатывать конфликты
* CRDT: бесконфликтные реплицируемые типы данных, которые объединяются автоматически

#### Вывод глобального порядка

Системы с несколькими лидерами обычно не могут надежно обеспечить линеаризуемость из-за фундаментального вызова установления глобального упорядочивания между одновременными записями к разным лидерам. Даже с точно синхронизированными часами сетевые задержки и дрейф часов делают практически невозможным гарантировать линеаризуемое упорядочивание. Некоторые системы, такие как Google's Spanner, пытаются это сделать, используя атомные часы и GPS для точной временной синхронизации, но это требует специализированного оборудования и сопровождается значительной операционной сложностью.

Гарантии согласованности зависят от того, как настроена репликация между write->write и write->read репликами. Она может варьироваться от самой быстрой и наиболее высокодоступной, где все реплицируется асинхронно, до высокосогласованной, где мы ждем ответа всех реплик, и все между ними.

Преимущества масштабирования чтения от систем с одним лидером применимы и здесь, поскольку фолловеры все еще могут обслуживать read-запросы. Однако сложность разрешения конфликтов и потеря естественного упорядочивания записей — уникальные вызовы. Кроме того, задержка репликации между лидерами может создавать временные несогласованности, которые читатели могут наблюдать.

Репликация с несколькими лидерами предпочтительнее перед беслидерной, когда вам нужно географическое распределение (каждый регион имеет своего лидера), когда у вас есть естественное разделение записей (разные лидеры обрабатывают разные типы данных) или когда вы хотите более структурированное разрешение конфликтов, чем то, что обычно предоставляют беслидерные системы.

## Беслидерная репликация

![[sharding_replication_4.png]]

Беслидерная репликация — это конфигурация, где каждая реплика может обслуживать как read, так и write запросы, так что это фактически репликация с несколькими лидерами, доведенная до крайности (каждая реплика — лидер).

Беслидерные системы устраняют единую точку отказа, которую представляют лидеры, но они требуют более сложной клиентской логики для обработки кворум-чтений и записей. Они наследуют вызовы разрешения конфликтов от систем с несколькими лидерами, но обрабатывают их по-другому через техники, такие как read repair и анти-энтропийные процессы. В отличие от систем на основе лидеров, нет специальной роли для любого узла, делая систему более симметричной и потенциально более простой в эксплуатации.

### Кворум-согласованность

Один важный факт в том, что беслидерная репликация, в отличие от репликации с несколькими лидерами, берет на себя ответственность за согласованность, вводя кворум-согласованность. Например, если у нас есть 3 реплики, мы можем ждать ответа только от 2 реплик при чтении и от 2 реплик при записи, и это даст нам гарантии согласованности (потому что по крайней мере одна read-реплика, которую мы запрашиваем, имеет последнее значение).

Read repair — это техника для обнаружения устаревших значений (которые возможны с кворумами) и их обновления при чтении с нескольких узлов. Анти-энтропия — это фоновый процесс, который сравнивает реплики и исправляет различия.

При работе с отказами узлов беслидерные системы используют две ключевые техники. Sloppy quorum позволяет записям продолжаться даже когда некоторые целевые узлы недоступны, временно записывая на разные доступные узлы. Hinted handoff обеспечивает, что когда оригинальные узлы восстанавливаются, они получают записи, которые временно хранились в другом месте, поддерживая согласованность без блокировки операций во время отказов.

### Разрешение конфликтов

Разрешение конфликтов в беслидерных системах использует похожие подходы к системам с несколькими лидерами (LWW, векторы версий, CRDT), но разрешение часто происходит во время операций чтения, а не записи. Поскольку нет лидера для координации конфликтов, клиенты или система должны обнаруживать и разрешать конфликты при чтении с нескольких реплик, делая read-операции потенциально более сложными.

## Шардинг

![[sharding_replication_5.png]]

Как масштабировать нашу систему, если слишком много данных, которые не помещаются в одной машине, или слишком много пропускной способности (запросов в секунду) для одного экземпляра? Подход называется шардинг, где мы распределяем нагрузку между несколькими экземплярами, где каждый экземпляр обрабатывает настроенное подмножество запросов (и/или данных).

Шардинг ортогонален репликации — у вас могут быть шардированные системы без репликации (каждый шард — это один экземпляр) или комбинировать шардинг с любой стратегией репликации (каждый шард может быть реплицирован с использованием подходов с одним лидером, несколькими лидерами или беслидерных подходов).

Но если мы делаем это, возникают некоторые вопросы естественным образом:

* Как мы разделяем данные и/или нагрузку и как добавляем/удаляем шарды?
* Как клиент узнает, какой шард должен обработать запрос (например, потому что он владеет данными)?
* Что если один шард получит непропорциональную долю нагрузки?
* Что если шард становится дисфункциональным (например, отключается)

Давайте рассмотрим все эти вопросы.

### Разделение данных и/или нагрузки

Есть несколько подходов к разделению нагрузки между экземплярами. Все они начинаются с того, что инженер выбирает ключ для сопоставления запросов с экземплярами, но алгоритмы фактического сопоставления варьируются:
* Указание диапазонов ключей, которые сопоставляются с экземплярами (например, A-M идет к шарду 1, N-Z — к шарду 2). Это хорошо работает, когда ключи равномерно распределены, но может создавать горячие точки, если определенные диапазоны обращаются чаще. Примеры включают HBase и некоторые конфигурации MongoDB.
* Вычисление хеша ключа и сопоставление его с экземплярами (например, hash(key) % num_shards). Это обеспечивает хорошее распределение, но делает невозможными диапазонные запросы, поскольку связанные ключи разбросаны по шардам. Добавление или удаление шардов требует значительного перемещения данных. Примеры включают Redis Cluster и некоторые развертывания Cassandra.
* Шардинг на основе каталога, где отдельная служба поиска сопоставляет ключи с шардами. Это обеспечивает гибкость в размещении данных и упрощает перебалансировку, но вводит дополнительный компонент, который может стать узким местом. Примеры включают некоторые распределенные файловые системы и ранние версии Google's Bigtable.
* Согласованное хеширование. Ради краткости мы не будем углубляться в это, но я просто хочу сказать, что это хорошо известная техника, которая назначает сегменты хешей ключей экземплярам, и ее расширение, называемое виртуальными узлами (или VNodes), обеспечивает, что добавление/удаление экземпляров не оставляет экземпляры с непропорциональной нагрузкой. Компромисс — увеличенная сложность в алгоритме хеширования, но он обеспечивает отличное распределение нагрузки и минимальное перемещение данных во время перебалансировки. Примеры включают Amazon DynamoDB, Apache Cassandra и Riak.

Добавление или удаление узлов варьируется по стратегии шардинга: шардинг на основе диапазонов требует разделения или объединения диапазонов и соответствующего перемещения данных; шардинг на основе хеша обычно требует перехеширования и перемещения значительной части данных; согласованное хеширование минимизирует перемещение данных, затрагивая только соседние узлы; в то время как подходы на основе каталога могут обновлять сопоставления без немедленного перемещения данных, позволяя постепенную перебалансировку.

### Маршрутизация запросов к их репликам

У нас может быть какой-то центральный компонент, ответственный за маршрутизацию (мы ранее упоминали шардинг на основе каталога). Поэтому клиенты должны связаться с ним, чтобы обменять ключ шардинга на ID экземпляра. Примеры включают:
• MongoDB's mongos роутер, который направляет запросы к соответствующим шардам
• Расширение Citus для PostgreSQL, которое обеспечивает маршрутизацию запросов
• Балансировщики нагрузки с sticky sessions, которые маршрутизируют на основе ключей сессии
• Сервисы Kubernetes, которые маршрутизируют к конкретным подам на основе атрибутов запроса

Такой центральный компонент не всегда нужен, есть два варианта сопоставления запросов с экземплярами без него:
* Клиенты могут вывести, к какому экземпляру они хотят подключиться на основе ключа. Это работает, когда алгоритм шардинга детерминирован и известен клиентам, например, с простым шардингом на основе хеша или известными разделениями диапазонов. Это предпочтительно, когда вы хотите минимизировать накладные расходы маршрутизации и иметь умных клиентов. Примеры включают клиенты Redis Cluster и некоторые клиентские библиотеки Cassandra, которые реализуют алгоритм согласованного хеширования локально.
* Наша система реализует умную peer-to-peer координацию, где клиенты могут связаться с любым узлом, и этот узел обрабатывает маршрутизацию внутренне. Клиенты поддерживают список всех IP-адресов узлов и могут связаться с любым случайным. Контактируемый узел либо обслуживает запрос (если он владеет данными), либо перенаправляет его к соответствующему шарду. Это хорошо работает для чтений и может работать для записей через техники, такие как hinted handoff, где узлы временно хранят записи для недоступных шардов. Примеры включают координирующие узлы Cassandra и координацию запросов Riak.

### Непропорциональная нагрузка и дисфункциональные экземпляры

Непропорциональная нагрузка возникает, когда определенные шарды получают значительно больше запросов, чем другие, часто из-за горячих точек в данных (знаменитые пользователи, популярный контент) или плохо выбранных ключей шардов. Стратегии смягчения включают выбор лучших ключей шардов, которые равномерно распределяют нагрузку, использование согласованного хеширования с виртуальными узлами для распределения горячих точек по нескольким физическим узлам, реализацию балансировки нагрузки на уровне приложения или создание дополнительных реплик для горячих шардов.

При работе с дисфункциональными экземплярами подход зависит от вашей стратегии репликации. В системах с репликацией другие реплики могут взять на себя обязанности отказавшего шарда. Без репликации затронутые данные становятся недоступными до восстановления экземпляра. Превентивные меры включают проверки состояния, автоматическое переключение на реплики шардов и поддержание нескольких реплик на шард. Некоторые системы реализуют circuit breaker'ы для быстрого обнаружения отказывающих экземпляров и маршрутизации трафика от них.

## Репликация встречает шардинг

![[sharding_replication_6.png]]

Репликация и шардинг — ортогональные концепции, но они могут дополнять друг друга. В этом разделе давайте обсудим, как их комбинировать для получения лучших качеств от обоих подходов:
• Отказоустойчивость от репликации обеспечивает доступность данных даже при отказе узлов
• Распределение нагрузки от шардинга обрабатывает наборы данных больше одной машины
• Масштабирование чтения через распределение реплик по шардам
• Географическое распределение, где каждый регион имеет реплицированные шарды

MongoDB хорошо иллюстрирует эту комбинацию: она использует replica sets (обычно 3 узла с одним primary и двумя secondary) для каждого шарда, обеспечивая как отказоустойчивость, так и распределение нагрузки. Запросы распределяются по шардам на основе ключа шарда, в то время как чтения могут обслуживаться secondary репликами внутри каждого шарда.

Apache Kafka предоставляет еще один отличный пример: топики разделены на партиции (шардинг), где каждая партиция может иметь несколько реплик на разных брокерах (репликация). Одна реплика служит лидером, обрабатывающим чтения и записи, в то время как фолловеры обеспечивают отказоустойчивость. Этот дизайн позволяет Kafka масштабироваться горизонтально путем добавления большего количества партиций и поддерживать высокую доступность через репликацию.

Другие примеры включают кластеры Elasticsearch (шарды с репликами), Cassandra (согласованное хеширование с фактором репликации) и распределенные SQL базы данных, такие как CockroachDB.

Основные компромиссы комбинирования репликации и шардинга включают увеличенную операционную сложность (управление как распределением шардов, так и согласованностью реплик), более высокие требования к ресурсам (несколько копий данных по нескольким шардам) и более сложные сценарии отказов (вам нужно обрабатывать как отказы шардов, так и отказы реплик). Однако преимущества часто перевешивают эти затраты для больших систем, которым нужны как высокая доступность, так и горизонтальная масштабируемость. Ключ — выбор правильного фактора репликации и стратегии шардинга для вашего конкретного случая использования и операционных возможностей.

## Выводы

Понимание распределенных систем фундаментально сводится к пониманию компромиссов между согласованностью, доступностью и устойчивостью к разделению — хотя мы можем расширить это, включив масштабируемость и операционную сложность. Каждый архитектурный паттерн, который мы исследовали, представляет разные точки на этих кривых компромиссов:

**Системы с одним экземпляром** предлагают самые сильные гарантии согласованности и простейшие операции, но жертвуют масштабируемостью и доступностью. Они идеальны для небольших приложений или когда сильная согласованность первостепенна.

**Репликация с одним лидером** обеспечивает золотую середину для нагрузок с интенсивным чтением, предлагая естественную линеаризуемость при добавлении масштабируемости чтения и базовой отказоустойчивости. Компромисс — ограниченная масштабируемость записи и потенциальные единые точки отказа.

**Репликация с несколькими лидерами** обеспечивает географическое распределение и масштабируемость записи, но вводит сложность разрешения конфликтов и отказывается от сильных гарантий согласованности. Она идеальна, когда вам нужно обрабатывать записи в разных регионах или есть естественно разделенные паттерны записи.

**Беслидерная репликация** максимизирует доступность и устраняет единые точки отказа через симметричную архитектуру, но требует сложной клиентской логики и тщательной настройки параметров кворума для балансировки согласованности и производительности.

**Шардинг** становится необходимым, когда данные или пропускная способность превышают возможности одной машины, но вводит сложность распределения данных, маршрутизации и перебалансировки. Выбор стратегии шардинга (диапазон, хеш, согласованное хеширование или на основе каталога) зависит от ваших паттернов доступа и операционных требований.

**Комбинированная репликация и шардинг** представляет архитектуру большинства крупномасштабных распределенных систем, предлагая как горизонтальную масштабируемость, так и отказоустойчивость за счет значительной операционной сложности.

Ключевое понимание в том, что нет универсально «лучшего» подхода — правильный выбор зависит от ваших конкретных требований для согласованности, доступности, масштабируемости и операционной простоты. Современные распределенные системы часто используют разные паттерны для разных компонентов: строго согласованное хранилище метаданных может использовать репликацию с одним лидером, в то время как пользовательские данные могут быть шардированы с беслидерной репликацией для максимальной доступности.

Понимая эти фундаментальные паттерны и их компромиссы, вы можете принимать обоснованные архитектурные решения и лучше рассуждать о поведении сложных распределенных систем в продакшне.