# Rate Limiting в масштабе: Уроки из продакшен SaaS-систем

## Как спроектировать Rate Limiting для SaaS-приложения

Как нам спроектировать SaaS-приложение, чтобы справиться с ростом входящего трафика? Очевидный ответ — проектировать с учётом текущей или планируемой нагрузки, будь то внезапный всплеск трафика или постепенный рост использования.

Но какова степень масштабируемости нашей системы? Какие внезапные всплески использования она может безопасно обработать? Проблема с горизонтальным масштабированием может заключаться в том, что системе может потребоваться время на запуск новых инстансов, что может быть долго и дорого. Альтернатива - обеспечение лимитов использования нашей системы. Архитектурная тактика для обеспечения таких ограничений называется Rate Limiting (иногда называемая throttling).

Существует множество ситуаций, которые могут вызвать опасные всплески трафика:

- Легитимные паттерны использования в "горячие" периоды (например, Black Friday в США)
- Viral моменты в социальных сетях или упоминания инфлюенсерами
- Вредоносный трафик, пытающийся обрушить наши системы
- Пользователи, пытающиеся запустить нагрузочное тестирование или автоматизацию с использованием наших API
- Боты-парсеры

В этой статье мы рассмотрим распространённые подходы и архитектуры для проектирования систем rate limiting и алгоритмов ограничения скорости.

## Распространённые предположения о rate limiting

- **Общий rate limiting** (то есть применяемый ко всем сервисам/эндпоинтам) обычно имеет смысл для простых случаев. Если мы хотим сделать rate limiting с учётом тенантов или реализовать пользовательскую логику приложения для проверки превышения лимитов, то часто лучше реализовать это внутри самого сервиса или использовать более сложный отдельный сервис rate limiting, поддерживающий пользовательские правила.
- **Слабые требования к согласованности**: не страшно, если мы пропустим несколько запросов. Мы можем спроектировать систему и для строгих гарантий (например, если каждый запрос очень дорогой), но это связано с увеличением стоимости и сложности (возможно, имеет смысл реализовывать это не на уровне общего rate limiting, а внутри логики бэкэнда).
- **Лимиты скорости должны чётко сообщаться клиентам** через стандартные заголовки (RateLimit-Limit, RateLimit-Remaining, RateLimit-Reset)
- **Разные эндпоинты могут требовать разных лимитов** в зависимости от их стоимости и важности.
- **Когда пользователь достигает лимита**, сервер вернёт код ошибки 429, указывающий, что было отправлено слишком много запросов.

## Измерения rate limiting

Существуют различные измерения, по которым можно ограничивать запросы:

**Ограничение на основе идентификации:**

- **IP-адрес**: Простой, но можно обойти; проблематичен с общим NAT
- **ID пользователя**: Требует аутентификации; наиболее точный для авторизованных пользователей
- **API-ключ**: Хорош для B2B API; позволяет различные уровни обслуживания
- **Тенант/Организация**: Необходим для мультитенантных SaaS

**Ограничение на основе ресурсов:**

- Лимиты, специфичные для эндпоинтов, основанные на вычислительной стоимости
- Стоимость операции, где сложные запросы потребляют больше "квоты"
- Иерархические лимиты (например, лимиты пользователей внутри лимитов тенантов)

## Проектирование системы rate limiting

Существует несколько подходов к построению систем rate limiting:

| Уровень реализации | Лучше всего для                                               | Ключевые компромиссы                                                       |
| ------------------ | ------------------------------------------------------------- | -------------------------------------------------------------------------- |
| API Gateway        | Простая защита, защита от DDoS                                | Централизованный, но менее гибкий; задержка сети                           |
| Отдельный сервис   | Сложные правила, общие для разных сервисов                    | Можно переиспользовать, но добавляет зависимость; потенциально узкое место |
| Внутри сервиса     | Пользовательская бизнес-логика, специфичные для сервиса нужды | Без задержки сети, но сложнее управлять глобально                          |

Для облачных SaaS-приложений часто имеет смысл гибридный подход: базовые лимиты скорости на уровне API gateway, с сложной бизнес-логикой rate limiting внутри сервисов, где это необходимо.

## Stateful vs. stateless подходы

**Stateless (используя внешнее хранилище, такое как Redis):**

- Горизонтально масштабируемый, простое деплоймент
- Сетевая задержка и внешняя зависимость
- Лучше для распределённых систем

**Stateful (хранение в памяти):**

- Очень низкая задержка, нет внешних зависимостей
- Требует sticky sessions, сложная перебалансировка
- Лучше для деплойментов с одним инстансом или там, где критична производительность

## Алгоритмы rate limiting

### Token Bucket

Корзина содержит токены, потребляемые запросами и пополняемые с постоянной скоростью. Допускает всплески трафика до уровня ёмкости корзины, сохраняя долгосрочные лимиты скорости. Использует ленивую оценку — не нужен фоновый процесс — "виртуальное" использование/пополнение токенов рассчитывается во время запроса.

**Лучше всего для**: Защиты бэкенд-систем, которые терпимы к всплескам

**Компромисс**: Простой и эффективный, но требует тщательного планирования ёмкости

### Leaky Bucket

Запросы заполняют корзину, которая "протекает" с постоянной скоростью, обеспечивая более плавное распределение лимитов. Может быть реализован с реальной очередью для хранения запросов или виртуально со счётчиками.

**Лучше всего для**: Защиты бэкенд-систем, которые не могут обрабатывать всплески

**Компромисс**: Плавная скорость, но может задерживать легитимный трафик

### Fixed Window Counter

Подсчёт запросов в фиксированных временных окнах (например, каждую минуту). Простой, но страдает от пограничных всплесков, где пользователи могут сделать запросы в размере двойного лимита, рассчитав время запросов вокруг границ окна.

**Лучше всего для**: Внутренних метрик, некритичного ограничения

**Компромисс**: Очень простой, но наименее точный

### Sliding Window Log

Самый точный способ, но при этом наиболее затратный по ресурсам. Хранит временные метки всех запросов и подсчитывает те, которые находятся в скользящем окне. 

**Лучше всего для**: Когда точность критична и объём запросов управляем

**Компромисс**: Идеальная точность, но высокое использование памяти

### Sliding Window Counter

Гибридный подход, использующий взвешенные средние текущего и предыдущего фиксированных окон. Эффективно аппроксимирует поведение скользящего окна.

**Лучше всего для**: Систем, требующих хорошей точности с разумным использованием ресурсов

**Компромисс**: Хороший баланс, но всё ещё аппроксимация

### GCRA (Generic Cell Rate Algorithm)

Используется Redis-cell, отслеживает, когда следующий запрос должен быть разрешён, на основе интервалов эмиссии. Обеспечивает плавное ограничение с точным временем ожидания.

**Лучше всего для**: Когда вам нужно очень плавный rate limiting с минимальной памятью

**Компромисс**: Более сложный для понимания, но очень эффективный

## Расчет подходящих лимитов скорости

Как рассчитать допустимый лимит для rate limiting системы? Все зависит от конкретной ситуации, но можем предложить несколько идей:

- Нагрузочное тестирование эндпоинтов для поиска точек отказа
- Если понятна точка отказа - применение запасов безопасности (т.е. 70-80% от этого максимума)
- Анализ исторических легитимных паттернов использования
- Начать с примерной оценки, и улучшать в процессе эксплуатации: анализ метрик и адаптация

## Сравнение решений Rate Limiting

Хочется отметить, что rate limiting это известная задача, и под нее написано уже множество решений: в большинстве случаев необязательно создавать все с нуля. Приводим перечень наиболее популярных продуктов: 

| Решение                | Лучше всего для                                   | Ключевое соображение                               |
| ---------------------- | ------------------------------------------------- | -------------------------------------------------- |
| Nginx rate limiting    | Простая защита на уровне веб-сервера              | Ограничено базовыми скоростями запросов/соединений |
| Redis-cell             | Распределённые системы, требующие согласованности | Требует инфраструктуры Redis                       |
| AWS API Gateway        | Serverless-приложения на базе AWS                 | Vendor lock-in, стоимость в масштабе               |
| Kong Gateway           | Сложные микросервисные архитектуры                | Более крутая кривая обучения                       |
| Cloudflare             | Глобальные, публичные API                         | Ограниченные возможности кастомизации              |
| Собственная реализация | Специфические бизнес-требования                   | Затраты на разработку и поддержку                  |

## Ключевые выводы

- **Начинайте с простого, развивайтесь по мере необходимости** — Не переусложняйте изначально
- **Выбирайте алгоритмы на основе требований** — например, Token bucket для большинства случаев, GCRA для плавного ограничения
- **Многоуровневая защита** — Несколько уровней обеспечивают лучшую защиту
- **Мониторьте и адаптируйтесь** — Лимиты скорости должны развиваться с паттернами использования
- **Балансируйте защиту с пользовательским опытом** — В идеале, лимиты должны редко замечаться легитимными пользователями

Rate limiting — это не только предотвращение злоупотреблений — это обеспечение качественного обслуживания для всех пользователей при защите вашей инфраструктуры. Лучшая система rate limiting невидима для "добропорядочных" клиентов, эффективно останавливая плохих.