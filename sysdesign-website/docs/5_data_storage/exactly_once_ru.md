# Семантика «точно один раз»

Обработка сообщений «точно один раз» решает фундаментальную проблему распределенных систем: обеспечение обработки сообщений ровно один раз, избегая как потери сообщений (не более одного раза), так и дублирования обработки (не менее одного раза). Современные системы обмена сообщениями, такие как Kafka, перенесли эту сложность на уровень инфраструктуры.

В данном анализе рассматривается реализация семантики «точно один раз» в компонентах системы, что обеспечивает техническую основу для реализации аналогичных гарантий в распределенных архитектурах.

## Основная проблема: почему сложно реализовать «точно один раз»

Фундаментальная проблема связана с распределенным характером систем обмена сообщениями. Рассмотрим следующую последовательность:

1. Производитель отправляет сообщение брокеру.
2. Брокер успешно сохраняет сообщение.
3. Сеть выходит из строя до того, как брокер может подтвердить получение.
4. Производитель предполагает сбой и повторяет попытку.
5. Результат: дублирование сообщения

Традиционные подходы требовали сложности на уровне приложения:
- **Ручная дедупликация**: отслеживание обработанных идентификаторов сообщений в базе данных
- **Идемпотентные операции**: бизнес-логика, предназначенная для обработки дубликатов
- **Двухфазная фиксация**: межсистемная координация транзакций с затратами на производительность

Современные системы обмена сообщениями решают эту проблему на уровне инфраструктуры с помощью предсказуемых, повторно используемых механизмов.

## Сторона производителя: генерация уникальных последовательных сообщений

С точки зрения производителя, семантика «точно один раз» достигается с помощью двух взаимодополняющих механизмов: **идемпотентной публикации** для операций с одним разделом и **транзакционной публикации** для операций с несколькими разделами.

### Идемпотентность производителя: порядковые номера для каждого раздела

Каждому производителю при запуске присваивается уникальный **идентификатор производителя (PID)**. Это не просто случайное число — оно управляется брокером и привязано к жизненному циклу производителя.

Вместе с каждой партией сообщений производитель включает **номер последовательности**, который начинается с 0 и монотонно увеличивается для каждого раздела:

```
Идентификатор производителя: 12345
Разделение 0: [seq=0] [seq=1] [seq=2] [seq=3] ...
Разделение 1: [seq=0] [seq=1] [seq=2] [seq=3] ...
```

Номера последовательности назначаются при **создании** пакета на стороне производителя, а не при его отправке. Это означает, что даже если производитель повторяет отправку пакета несколько раз из-за таймаутов сети, номера последовательности остаются неизменными.

Такая конструкция позволяет справиться с наиболее распространенными сценариями сбоев:
- **Повторные попытки сети**: один и тот же номер последовательности отправляется несколько раз
- **Перезапуск производителя**: новый PID предотвращает путаницу со старыми последовательностями
- **Частичные сбои брокера**: отслеживание последовательности сохраняется после большинства перезапусков брокера

### Сеансы производителя: обработка сбоев и зомби

Система идентификаторов производителя более сложна, чем кажется на первый взгляд. При сбое и перезапуске производителя может появиться «зомби»-производитель, который продолжает отправлять сообщения после запуска нового экземпляра.

Эта проблема решается с помощью **номеров эпохи** — отдельного 16-битного счетчика (отличного от PID), который увеличивается каждый раз, когда инициализируется производитель с тем же `transactional.id` (настраиваемый пользователем строковый идентификатор, представляющий логическую идентичность службы, например «payment-service» для всех подсистем в развертывании K8s):

```
Сессия 1: PID=12345, Эпоха=0 (начинает отправлять сообщения)
↓ (продюсер вылетает)
Сессия 2: PID=12345, Эпоха=1 (запускается новый экземпляр)
↓ (сообщения из сессии 1 теперь отклоняются)
```

Когда у производителя есть `transactional.id`, **PID остается неизменным** при перезапусках (что обеспечивает непрерывность отслеживания последовательности), но **эпоха увеличивается** (что обеспечивает защиту от зомби). Без `transactional.id` при каждом перезапуске получается совершенно новый PID и теряются гарантии идемпотентности.

**Механизм ограждения**: более высокие номера эпохи автоматически «ограждают» предыдущие экземпляры. Это предотвращает повреждение потока сообщений зомби-продюсерами, гарантируя, что только последняя сессия продюсера может успешно отправлять сообщения — любые задержанные или дубликаты сообщений из старых сессий отклоняются, сохраняя гарантии точности даже при сбоях и перезапусках продюсера.

### Транзакционная публикация: атомарность нескольких разделов

Для операций, охватывающих несколько разделов или тем, производители используют **транзакционные API**. Производитель координирует свои действия с **координатором транзакций**, чтобы обеспечить атомарность фиксации во всех задействованных разделах. Важно, что транзакции используют гарантии «точно один раз» в отдельных разделах, чтобы обеспечить атомарность в нескольких разделах и гарантии «точно один раз». Это достигается с помощью распределенных транзакций, но ограничено брокерами Kafka в пределах одного кластера — не распространяется на внешние системы, такие как базы данных.
**Поток транзакций с точки зрения производителя**:
1. **Начало транзакции**: получение идентификатора транзакции от координатора
2. **Отправка сообщений**: в несколько разделов/тем (все помеченные как часть этой транзакции) — гарантируется, что они будут отправлены ровно один раз
3. **Фиксация транзакции**: сообщение координатору о необходимости атомарной фиксации во всех разделах
4. **Обработка ответа координатора**: успех означает, что все разделы зафиксированы, сбой означает, что все разделы отменены

Транзакции могут охватывать совершенно разные темы, а не только разделы в пределах одной темы. Это позволяет осуществлять атомарные сложные многосервисные операции.

## Сторона брокера: проверка, координация и хранение

С точки зрения брокера, семантика «точно один раз» требует поддержания дополнительного состояния и реализации сложной логики проверки.

### Проверка порядкового номера

Каждый брокер хранит в памяти карту последних зафиксированных порядковых номеров для каждой активной комбинации PID/раздела. При поступлении пакета сообщений:

- **Если порядковый номер < ожидаемый**: дубликат — отбросить без уведомления
- **Если порядковый номер = ожидаемый**: также дубликат — уже обработан
- **Если порядковый номер > ожидаемый**: обнаружен пропуск — отклонить с ошибкой
- **Если последовательность = ожидаемая + 1**: обработать как обычно и инкрементировать

**Сохранение для восстановления после сбоя**: номера последовательностей периодически сохраняются в файлах `.snapshot`. При сбое и перезапуске брокера он восстанавливает карту отслеживания последовательностей, считывая снимки и воспроизводя сегменты журнала.

**Управление памятью**: брокер отслеживает последовательности только для активных производителей. Старые сопоставления PID/разделов очищаются после истечения сеансов производителей.

### Координация транзакций

**Координатор транзакций** — это специальный компонент брокера, который управляет жизненным циклом многораздельных транзакций. Он поддерживает состояние транзакций в реплицированной внутренней теме под названием `__transaction_state`.

**Прогресс состояния транзакции**:
```
Пусто → Выполняется → PrepareCommit → CompleteCommit
↓
PrepareAbort → CompleteAbort
```

**Реализация двухфазной фиксации**:
1. **Фаза 1 (подготовка)**: координатор записывает «PrepareCommit» в журнал транзакций
2. **Фаза 2 (фиксация)**: координатор записывает маркеры фиксации во все участвующие разделы
3. **Завершение**: координатор записывает «CompleteCommit» в журнал транзакций

Координатор должен обрабатывать случай, когда координатор транзакций сам выходит из строя в середине транзакции. Реплицированный журнал транзакций позволяет координаторам восстановления завершить или прервать незавершенные транзакции.

### Дедупликация транзакций

Здесь брокер реализует важную идею, что **атомарность сама по себе не обеспечивает точное выполнение**. Даже если транзакция фиксируется атомарным образом во всех разделах, производитель может не получить подтверждение успеха и повторить всю транзакцию.

**Проверка дедупликации**: когда производитель пытается зафиксировать транзакцию, координатор проверяет:
- Уже ли эта сессия производителя (PID + Epoch) зафиксировала транзакцию с этой последовательностью?
- Если да: вернуть успех без повторного выполнения (идемпотентность)
- Если нет: продолжить обычную двухфазную фиксацию (атомарность)

Именно эта комбинация идемпотентности на уровне транзакций и атомарных фиксаций обеспечивает истинную семантику «точно один раз».

### Контрольные записи и изоляция потребителей

Для потребителей, настроенных с помощью `isolation.level=read_committed`, брокеры реализуют дополнительную логику:

**Последний стабильный смещение (LSO)**: потребители могут читать только до смещения первого сообщения, принадлежащего открытой (незафиксированной) транзакции. Это предотвращает чтение сообщений, которые могут быть впоследствии прерваны.

**Фильтрация контрольных записей**: брокеры отфильтровывают прерванные транзакционные сообщения перед отправкой их потребителям. Потребители никогда не видят сообщения из прерванных транзакций.
**Маркеры транзакций**: специальные записи управления указывают границы транзакций (фиксация/прерывание), но не отображаются в приложениях в виде обычных сообщений.

## Сторона потребителя: обработка сообщений ровно один раз

С точки зрения потребителя, семантика «ровно один раз» касается не только доставки сообщений, но и обеспечения атомарности обработки сообщений и обновления состояния.

### Задача потребителя

Даже при точном однократном доставке от брокера потребители сталкиваются со своей собственной задачей:
1. Прием и обработка сообщений
2. Обновление состояния приложения (база данных, кэш и т. д.)
3. Фиксация смещений потребителя

**Сценарий сбоя**: если потребитель выходит из строя после шага 2, но до шага 3, он повторно обработает те же сообщения, не зная, что они уже были обработаны.

### Обработка потребителем

Kafka обеспечивает семантику «точно один раз» от начала до конца (производитель → брокер → потребитель) при правильной настройке. Однако потребители все равно могут видеть дубликаты сообщений, если они не управляют смещениями правильно — это проблема настройки и использования, а не ограничение гарантий «точно один раз» Kafka. Мы подробнее остановимся на этом ниже.

**Как работает доставка «точно один раз» со стороны потребителя**:
- Потребители с `isolation.level=read_committed` видят только сообщения из зафиксированных транзакций
- Брокер отслеживает смещения потребителей и доставляет только те сообщения, которые еще не были подтверждены
- Когда смещения зафиксированы (вручную или автоматически), эти сообщения не доставляются повторно
- Если потребитель выходит из строя до фиксации смещений, он получит те же сообщения снова

Возможно, вы уже задаетесь вопросом: что произойдет, если приложение завершит работу после фиксации изменений в бизнесе (например, снятие средств со счета), но до подтверждения сообщения Kafka? Мы можем получить худший результат: изменение в бизнесе произошло, но Kafka повторно доставит сообщение (при перезапуске приложения), что может привести к дублированию обработки (двойному снятию средств).

Даже при такой доставке «точно один раз» между обработкой сообщений и фиксацией смещений остается зазор, который может привести к дублированию обработки. Существует несколько решений этой проблемы:

1. **Транзакционный подход Kafka**: вместо того, чтобы выполнять изменения в коде напрямую, мы можем делать это асинхронно: отправлять сообщение другому компоненту, который выполнит это неидентичное изменение. Мы можем использовать транзакции Kafka для координации фиксации смещений (подтверждения, что сообщение прочитано) с созданием этого бизнес-сообщения. Это сделает все операции в Kafka атомарными.
2. **Ручное управление смещениями**: храните смещения потребителей в той же системе, что и состояние вашего бизнеса (например, в базе данных), и фиксируйте их вместе с помощью внешних транзакций.
3. **Подход с использованием идемпотентности**: разработайте логику обработки так, чтобы безопасно обрабатывать дубликаты сообщений, сделав систему устойчивой к повторной обработке независимо от времени смещения.

## Вопросы производительности и эксплуатации

Семантика «точно один раз» не бесплатна. Вот что вы на самом деле платите за эти гарантии:

**Снижение пропускной способности**: идемпотентные производители добавляют небольшую накладную накладную в размере 2–5 % (в основном за счет учета порядковых номеров), но полные транзакции могут замедлить работу на 10–20 %. Эта координация и двухфазный процесс фиксации занимают время.

**Затраты на память**: брокеры должны отслеживать порядковые номера для каждой активной комбинации производителя и раздела, хотя обычно это не занимает много места. Более серьезной проблемой является необходимость буферизации потребителями сообщений из текущих транзакций — при длительных транзакциях это может быстро занять много памяти.

**Тонкости настройки**: нельзя просто переключить переключатель и получить точно однократное выполнение. Идемпотентность производителя требует, чтобы `max.in.flight.requests` был равен 5 или меньше для поддержания порядка сообщений. Таймауты транзакций сложно настроить — слишком короткие приводят к прерыванию легитимных операций, слишком длинные — к блокировке потребителей неработающими производителями. Кроме того, необходимо использовать `acks=all`, иначе гарантии долговечности теряются.
Вывод: семантика «точно один раз» добавляет сложность и накладные расходы, но для систем, где дубликаты или потери создают реальные проблемы для бизнеса, это обычно оправдано.

## Как другие системы обмена сообщениями решают эту проблему

Kafka — не единственная система на рынке, но она определенно лидирует, когда речь идет о семантике «точно один раз». Вот как выглядят конкуренты:

**Многие современные системы также поддерживают точно однократное выполнение**:

**Apache Pulsar** использует более простой подход — автоматическую дедупликацию на уровне брокера с использованием идентификаторов сообщений. Это менее сложно, чем система Kafka, но гораздо проще в использовании. Вы получаете базовую точность однократного выполнения без сложной настройки.

**NATS JetStream** предлагает гибкие окна дедупликации, которые можно настраивать, включая «бесконечную дедупликацию», если вы не хотите видеть одно и то же сообщение дважды. Это мощный инструмент, но требует более тщательной настройки.

**Amazon Kinesis** — вероятно, ближайший конкурент Kafka, но он не обеспечивает полную точность доставки. Он имеет порядковые номера для каждого фрагмента (аналогично подходу Kafka для каждой партиции) и обеспечивает доставку не реже одного раза, но вам все равно нужно реализовать собственную логику дедупликации в приложениях.

**Amazon SQS FIFO** обеспечивает дедупликацию с помощью идентификаторов дедупликации сообщений — вы либо предоставляете свой собственный идентификатор, либо AWS генерирует его на основе содержимого сообщения. Но есть один нюанс: это работает только в течение 5-минутного окна и ограничено одной очередью. Подходит для простых случаев использования, но не для сложных распределенных операций.

**Amazon SNS FIFO** работает аналогично SQS FIFO — использует идентификаторы дедупликации для предотвращения дублирования публикаций в течение 5 минут. Однако это только предотвращает публикацию дубликатов сообщений в теме; не обеспечивает атомарность между темами, как транзакции Kafka.

**Системы, которые обходят эту проблему**:

**RabbitMQ** и **ActiveMQ** в основном сдаются и говорят: «Разберись сам». Они обеспечивают доставку «хотя бы один раз» и ожидают, что вы будете обрабатывать дедупликацию в коде приложения. Это старый подход, который перекладывает всю сложность на вас.

**Вывод**: большинство систем предоставляют либо базовую дедупликацию, либо атомарные операции, но не и то, и другое. Инновация Kafka заключалась в том, что для реального решения проблемы «точно один раз» необходимо сочетание идемпотентности и атомарности.

## Когда применять семантику «точно один раз»

Семантика «точно один раз» обеспечивает высокую согласованность, но влечет за собой сложность и снижение производительности. Сценарии применения требуют тщательной оценки.

**Критические случаи использования, требующие гарантий «точно один раз»:**
- **Финансовые транзакции**: обработка платежей, торговые системы, бухгалтерский учет, где дублирование обработки приводит к денежным потерям
- **Управление запасами**: уровни запасов в электронной коммерции, системы цепочки поставок, где двойная обработка приводит к перепродаже
- **Системы обеспечения соответствия**: медицинские записи, финансовая отчетность, системы аудита, требующие нормативной точности

**Случаи использования, в которых точность выполнения может быть ненужной:**
- **Аналитика и метрики**: крупномасштабная обработка данных, где незначительные отклонения в точности не влияют на бизнес-решения
- **Операционный мониторинг**: системные журналы, метрики производительности, где низкая задержка имеет приоритет над идеальной точностью
- **Некритические уведомления**: уведомления по электронной почте, обмен сообщениями, где дублирование доставки представляет собой приемлемое неудобство

## Ключевые выводы

1. **Exactly-once требует как идемпотентности, так и атомарности** — ни один из этих механизмов в отдельности не является достаточным
2. **Номера последовательности производителя** обеспечивают основу для устранения дубликатов в разделах
3. **Координация транзакций** распространяет гарантии exactly-once на несколько разделов и тем
4. **Важность дизайна потребителя** — даже доставка exactly-once требует атомарной обработки и управления смещением
5. **Компромиссы в производительности реальны** — точно однократная доставка сопровождается измеримыми накладными расходами в пропускной способности и задержках
6. **Решения на уровне инфраструктуры** масштабируются лучше, чем перенос сложности на каждое приложение

Понимание этих механизмов дает вам инструменты для оценки систем обмена сообщениями, проектирования отказоустойчивых приложений и реализации аналогичных гарантий в вашей собственной архитектуре распределенных систем.