# Распределенные системы поиска: архитектура, лежащая в основе современных приложений

Поиск товаров на Amazon, поиск ресторанов на DoorDash и запросы к корпоративной базе знаний — все это основано на распределенных системах поиска, которые одновременно обрабатывают миллионы похожих запросов. Эти системы прошли долгий путь от простого сопоставления ключевых слов — современные архитектуры сочетают традиционный текстовый поиск с семантическим пониманием, при этом обеспечивая время отклика менее секунды в глобальном масштабе.

За последние годы сфера поиска претерпела кардинальные изменения. Традиционные системы на основе ключевых слов быстро превращаются в платформы, которые понимают не только слова, но и намерения. Бессерверные архитектуры устраняют операционные издержки. Векторные базы данных открывают возможности для совершенно новых парадигм поиска. В этом техническом обзоре подробно рассматриваются архитектуры, алгоритмы и компромиссные решения, лежащие в основе современного поиска в больших масштабах.

## Основы поиска: от ключевых слов к пониманию

Современные системы поиска должны обрабатывать широкий спектр типов запросов, которые отражают то, как пользователи на самом деле ищут информацию. Поиск по ключевым словам остается основополагающим — пользователи по-прежнему вводят «чехол для iPhone 15» или «программное обеспечение для управления проектами», — но теперь поисковые системы интерпретируют намерения, обрабатывают опечатки и понимают синонимы. Запрос «врач рядом» требует контекста местоположения, а «лучший ноутбук для программирования» — понимания категорий продуктов и сценариев использования.

### Эволюция релевантности

Релевантность поиска прошла несколько этапов развития. Ранние системы полагались на точное совпадение ключевых слов, часто возвращая результаты в случайном порядке. Внедрение TF-IDF (Term Frequency-Inverse Document Frequency, частота термина — обратная частота документа) принесло статистическую релевантность, ранжируя документы на основе важности терминов как в отдельных документах, так и во всей коллекции.

BM25 (Best Matching 25) улучшил TF-IDF, устранив насыщение частоты терминов — дополнительные вхождения термина приносят уменьшающуюся отдачу — и включив нормализацию длины документа. Этот алгоритм остается основой большинства текстовых поисковых систем, хотя современные реализации включают в себя десятки дополнительных сигналов ранжирования.

Машинное обучение привело к появлению подходов «обучение ранжированию», которые оптимизируют релевантность с помощью данных о переходах по ссылкам и сигналов о поведении пользователей. Эти системы могут научиться тому, что пользователи, нажимающие на третий результат вместо первого, указывают на проблему с упорядочением по релевантности, и постоянно улучшать качество поиска с помощью обратной связи от пользователей.

### Обработка и анализ запросов

Прежде чем документы могут быть проиндексированы, как запросы, так и контент проходят сложный анализ. Конвейеры текстового анализа токенизируют входные данные, нормализуют регистр, удаляют стоп-слова и применяют стемминг или лемматизацию. Запрос «кроссовки» может быть преобразован с включением связанных терминов, таких как «спортивная обувь» или «кеды».

Пользовательские анализаторы позволяют оптимизировать поиск для конкретных областей. Платформы электронной коммерции могут рассматривать «iPhone-15» и «iPhone 15» как одно и то же, в то время как поиск юридических документов сохраняет точную пунктуацию. Для поддержки нескольких языков требуются языковые анализаторы, понимающие различные грамматические структуры и наборы символов.

Современная обработка запросов также включает классификацию намерений. Поиск по запросу «Apple» может относиться к фрукту или технологической компании, что требует контекста из истории пользователя, содержимого текущей страницы или явного устранения неоднозначности. Распознавание именованных сущностей помогает идентифицировать людей, места и организации в запросах, обеспечивая более точное сопоставление.

## Elasticsearch: стандарт поисковых систем

Elasticsearch стал де-факто стандартом для поисковой инфраструктуры, обеспечивая работу всего, от каталогов продуктов электронной коммерции до систем управления знаниями в предприятиях. Его успех основан на сочетании мощных поисковых возможностей и распределенной архитектуры, которая масштабируется по горизонтали.

### Основная архитектура и модель данных

Elasticsearch организует данные в индексы — логические контейнеры, похожие на таблицы базы данных. Каждый индекс состоит из документов, хранящихся в виде объектов JSON, что обеспечивает гибкость для различных структур данных. В отличие от жестких схем баз данных, динамическое сопоставление Elasticsearch автоматически определяет типы полей и создает соответствующие индексы.

Базовая структура данных использует инвертированные индексы — ту же технологию, что и поисковая система Google. Вместо последовательного хранения документов система создает сопоставления терминов и документов для каждого поля. При индексировании описания продукта, содержащего «беспроводные Bluetooth-наушники», Elasticsearch создает записи, сопоставляющие каждый термин с ID документа, что позволяет быстро находить термины в миллионах документов.

Типы полей определяют, как индексируются и ищутся данные. Текстовые поля подвергаются полному анализу для поиска, а поля ключевых слов позволяют выполнять точное сопоставление и агрегирование. Числовые, даты и булевы поля поддерживают запросы по диапазону и сортировку. Вложенные и объектные типы обрабатывают сложные структуры данных, а специализированные типы, такие как geo_point, позволяют выполнять поиск по местоположению.

### Шардинг и распределение

Модель распределения Elasticsearch основана на шардинге — разделении индексов на более мелкие независимые единицы, распределенные по узлам кластера. Каждый первичный шард функционирует как полный индекс Lucene, независимо обрабатывая как чтение, так и запись. Система использует маршрутизацию на основе хеширования для обеспечения равномерного распределения данных: `shard = hash(routing_key) % number_of_primary_shards`.

Реплики шардов обеспечивают отказоустойчивость и повышенную пропускную способность чтения. Кластер автоматически балансирует шарды между узлами, повышая статус реплик до первичных при сбоях. Такая архитектура позволяет линейно масштабировать систему: добавление узлов увеличивает как емкость хранилища, так и пропускную способность запросов.

Выполнение запросов происходит по схеме «разброс-сбор». Координационный узел принимает запросы, определяет соответствующие шарды, распределяет запросы по кластеру и агрегирует результаты. Такой распределенный подход позволяет выполнять запросы к петабайтам данных с временем отклика менее секунды.

### Расширенные возможности поиска

Elasticsearch предоставляет сложные типы запросов, выходящие за рамки простого сопоставления текста. Булевы запросы объединяют несколько условий с помощью операторов AND, OR и NOT. Диапазонные запросы фильтруют числовые и даты поля. Нечеткие запросы обрабатывают опечатки и вариации, а запросы с подстановочными знаками и регулярными выражениями позволяют выполнять сопоставление шаблонов.

Агрегации позволяют выполнять аналитические запросы по результатам поиска. Агрегации терминов подсчитывают количество вхождений значений полей, а агрегации метрик вычисляют суммы, средние значения и процентили. Агрегации корзин группируют результаты по диапазонам дат, географическим регионам или настраиваемым критериям. Эти возможности превращают Elasticsearch из поисковой системы в полноценную аналитическую платформу.

Функции полнотекстового поиска включают сопоставление фраз, запросы по близости и выделение. Запрос «more-like-this» находит похожие документы на основе анализа содержания. Многополевой поиск может выполнять запросы по нескольким полям с разными коэффициентами повышения, а межполевой поиск обрабатывает несколько полей как одно логическое поле.

Современный Elasticsearch интегрирует возможности на базе LLM, которые расширяют возможности поиска за пределы сопоставления ключевых слов. Плотные векторные поля поддерживают семантический поиск с использованием вложений, сгенерированных такими моделями, как BERT или text-embedding-ada-002 от OpenAI. Пользователи могут искать «бюджетный транспорт» и находить документы о «доступных автомобилях» даже без общих ключевых слов.

## Решения для поиска в базах данных

Многие организации предпочитают расширять существующие базы данных с помощью функций поиска, а не поддерживать отдельную инфраструктуру поиска. Такой подход снижает сложность эксплуатации и позволяет использовать существующий опыт и модели безопасности.

### Эволюция поиска в PostgreSQL

PostgreSQL предлагает сложные возможности полнотекстового поиска с помощью типов данных tsvector и tsquery. Индексы GIN (Generalized Inverted Index) обеспечивают эффективный текстовый поиск с ранжированием и сопоставлением фраз. Система поддерживает несколько языков, пользовательские словари и алгоритмы стемминга.

Последние версии PostgreSQL включают параллельное выполнение запросов для текстового поиска, что значительно повышает производительность на многоядерных системах. Расширения, такие как pg_trgm, предоставляют возможности нечеткого сопоставления, а pg_search (ParadeDB) обеспечивает производительность, сопоставимую с Elasticsearch, с помощью библиотеки Tantivy.

pgvector позволяет осуществлять семантический поиск по векторному сходству. Поддерживая алгоритмы HNSW и IVFFlat, он обрабатывает вложения до 16 000 измерений с настраиваемыми функциями расстояния. Эта интеграция позволяет объединить традиционный текстовый поиск с семантическим сходством в одном запросе.
Для организаций, уже использующих PostgreSQL, встроенные возможности поиска предлагают убедительные преимущества в простоте эксплуатации, согласованности данных и снижении затрат. Однако масштабируемость по-прежнему ограничена одноузловыми развертываниями или сложными стратегиями шардинга.

### Интегрированный подход MongoDB

MongoDB Atlas Search интегрирует Apache Lucene непосредственно в платформу базы данных. Система создает индексы поиска, синхронизированные с операционными данными через потоки изменений, обеспечивая согласованность и позволяя независимо масштабировать операции поиска.

Atlas Search поддерживает как текстовый, так и векторный поиск с реализацией HNSW для векторов до 8192 измерений. Этап агрегации `$vectorSearch` позволяет выполнять сложные запросы, сочетающие традиционные фильтры с семантическим поиском. Динамическое сопоставление автоматически определяет типы полей и создает соответствующие индексы.

Интеграция предоставляет уникальные преимущества для приложений, уже использующих MongoDB. Документы можно искать и извлекать через один и тот же API, что устраняет сложность обслуживания отдельной инфраструктуры поиска. Встроенные функции безопасности и репликации используют зрелые операционные возможности MongoDB.

## Коммерческие платформы поиска

Сложность построения и обслуживания инфраструктуры поиска породила множество коммерческих платформ, предлагающих управляемые возможности поиска с расширенными функциями и глобальным распространением.
### Фокус Algolia на производительности

Распределенная поисковая сеть Algolia достигает исключительной производительности благодаря глобально распределенной инфраструктуре. Используя репликацию на основе консенсуса в более чем 25 дата-центрах, платформа обеспечивает среднее время отклика сервера 6,7 мс, при этом 90% запросов выполняются менее чем за 15 мс.
Механизм консенсуса трех серверов обеспечивает согласованность данных при сохранении высокой доступности. Репликация в реальном времени синхронизирует данные по сети в течение нескольких минут, автоматически направляя пользователей на ближайший сервер. Эта инфраструктура поддерживает более 2 миллиардов запросов в месяц.
Algolia отличается удобством для разработчиков благодаря комплексным SDK и компонентам пользовательского интерфейса мгновенного поиска. Платформа автоматически обрабатывает отклонение запросов, кэширование результатов и постепенное уточнение запросов. Расширенные функции включают толерантность к опечаткам, фасетный поиск и персонализацию на основе поведения пользователей.

## Предложения по управляемому поиску

Крупные поставщики облачных услуг и поисковых систем предлагают управляемые поисковые сервисы, которые сочетают в себе функциональность и простоту эксплуатации, устраняя операционные затраты на управление кластерами и предоставляя возможности корпоративного уровня.
### Elastic Cloud

Elastic Cloud предоставляет официальный управляемый сервис Elasticsearch, предлагающий полный набор функций открытого ПО Elasticsearch с корпоративной безопасностью, мониторингом и поддержкой. Платформа работает на AWS, Google Cloud и Microsoft Azure, что позволяет развертывать ее в предпочтительных облачных средах, сохраняя при этом функциональность.

Сервис предлагает несколько вариантов развертывания, включая выделенные кластеры, бессерверный поиск и решения для наблюдаемости. Бессерверный Elasticsearch автоматически масштабирует вычислительные ресурсы и хранилище независимо друг от друга, устраняя необходимость планирования емкости и сохраняя предсказуемую цену за запрос. Этот подход особенно выгоден для приложений с переменной или непредсказуемой нагрузкой на поиск.

Сильная сторона платформы заключается в предоставлении полного набора функций Elasticsearch без сложности эксплуатации. Команды получают доступ к новейшим функциям сразу после их выпуска, а автоматические обновления и патчи безопасности устраняют затраты на обслуживание.

### Amazon Web Services

Amazon OpenSearch Service предоставляет полностью управляемые кластеры Elasticsearch с автоматическим масштабированием, резервным копированием и функциями безопасности. Сервис интегрирован с CloudWatch для мониторинга, IAM для безопасности и VPC для сетевой изоляции. Недавние усовершенствования включают варианты развертывания без серверов и возможности векторного поиска.
Плагин нейронного поиска позволяет выполнять семантический поиск с использованием предварительно обученных моделей или настраиваемых встраиваний. Обнаружение аномалий выявляет необычные паттерны в поведении поиска, а тонкий контроль доступа позволяет развертывать многопользовательские системы с безопасностью на уровне документов.

### Microsoft Azure

Azure AI Search демонстрирует облачный подход с встроенными когнитивными навыками для анализа изображений, OCR и обработки текста. Архитектура навыков платформы позволяет создавать сложные конвейеры обработки контента, автоматически извлекая структуру из неструктурированного контента.

Интеграция с Azure OpenAI обеспечивает возможность запросов на естественном языке и функции резюмирования. Сервис отличается превосходным пониманием документов с автоматическим распознаванием сущностей и поддержкой более 60 языков.

### Google Cloud Platform

Google Vertex AI Search использует опыт веб-поиска для корпоративных приложений. Платформа сочетает в себе поиск и диалоговый искусственный интеллект, обрабатывая как структурированные, так и неструктурированные данные, а также предоставляя базовые возможности через информационный корпус Google.

Сервис отличается высокой эффективностью понимания документов и обработки естественного языка, а также автоматической оценкой качества и настройкой релевантности на основе взаимодействия с пользователем. Интеграция с сервисами машинного обучения Google обеспечивает сложные функции персонализации и рекомендаций.
