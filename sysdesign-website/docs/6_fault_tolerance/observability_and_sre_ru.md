# Observability и SRE

## Обзор

Традиционный мониторинг часто не справляется с задачей в распределенных системах, когда это наиболее необходимо. Сервисы могут выглядеть исправными по показателям инфраструктуры, но пользователи испытывают снижение производительности из-за сложных взаимодействий компонентов. Observability вышла за рамки простого мониторинга и стала необходимым условием для эксплуатации современных систем.

Эволюция от традиционного мониторинга к современной observability представляет собой значительный сдвиг в эксплуатации распределенных систем. Традиционный мониторинг задает вопрос «Это не работает?», а observability — «Почему это не работает и что я могу с этим сделать?».

## Четыре столпа observability

Observability состоит из четырех основных инструментов отладки, каждый из которых служит конкретной цели и вместе обеспечивает всестороннее понимание системы во время сбоев.

### Метрики: жизненные показатели системы

Метрики предоставляют непрерывный поток числовых данных, отражающих текущее и историческое поведение системы. Они обеспечивают экономичный сбор данных, простое агрегирование, а также эффективные возможности выявления тенденций и оповещения.

Ценность метрик заключается в их простоте и возможности агрегирования. Одиночные числа могут указывать на состояние системы, узкие места в производительности или качество пользовательского опыта. Эффективный сбор метрик фокусируется на измерениях, отвечающих на конкретные бизнес-вопросы, а не на беспорядочном сборе данных.

**Четыре золотых сигнала** (от Google SRE) обеспечивают комплексную основу для мониторинга:

**Задержка** измеряет время обработки запроса от момента получения до ответа, включая время прохождения по сети, время обработки и задержки в очереди. Ухудшение времени отклика напрямую влияет на пользовательский опыт даже при исправной работе системы. Среднее время отклика может вводить в заблуждение из-за выбросов; процентильные измерения (P95, P99) дают более точное представление о худших показателях производительности, влияющих на удовлетворенность пользователей.

**Трафик** количественно оценивает нагрузку на систему через количество запросов или операций в единицу времени. HTTP-сервисы обычно измеряют количество запросов в секунду (RPS). Показатели, значимые для бизнеса, включают: количество заказов в электронной коммерции в минуту в часы пик, количество одновременных потоков видео и потребление пропускной способности, количество запросов к базе данных или транзакций в секунду.

**Ошибки** представляют собой долю неудачных запросов от общего числа запросов. Значимость ошибок варьируется: ошибки 404, связанные с отсутствием профилей пользователей, отличаются от ошибок 500, связанных с сбоями в работе платежной системы. Классификация ошибок по степени воздействия включает ожидаемые ошибки (сбои проверки ввода пользователя), временные ошибки (временные проблемы с сетью) и критические ошибки (сбои основных функций).

**Насыщенность** измеряет использование системных ресурсов, включая ЦП, память, ввод-вывод диска, пропускную способность сети или ограничения, специфичные для приложения, такие как использование пула подключений к базе данных, насыщенность пула потоков или глубина очереди. Цель состоит в выявлении ограничений ресурсов до того, как они станут узкими местами производительности.

### Золотые сигналы по масштабу сервиса

<!-- TODO: diagram image missing for this Mermaid block -->
<!--
Original Mermaid code:
``` mermaid
graph LR
    A["&lt;b>Малый&lt;/b>&lt;br/>1-10 RPS&lt;br/>P95 &lt; 500ms&lt;br/>0.5-1% ошибки&lt;br/>Оповещение при 70%"] 
    
    B["&lt;b>Средний&lt;/b>&lt;br/>10-1K RPS&lt;br/>P95 &lt; 200ms&lt;br/>0.1-0.5% ошибки&lt;br/>Оповещение при 60%"]
    
    C["&lt;b>Крупный&lt;/b>&lt;br/>1K-100K RPS&lt;br/>P95 &lt; 100ms&lt;br/>0.01-0.1% ошибки&lt;br/>Оповещение при 50%"]
    
    D["&lt;b>Глобальный&lt;/b>&lt;br/>100K+ RPS&lt;br/>P95 &lt; 50ms&lt;br/>&lt;0.01% ошибки&lt;br/>Оповещение при 40%"]
    
    A --> B --> C --> D
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#fff3e0
    style D fill:#f1f8e9
```
-->

**Примеры использования:**

- **Небольшие сервисы**: MVP стартапов, внутренние панели администрирования, API для проверки концепции, среды разработки, инструменты для команд (справочник компании, отслеживание расходов)

- **Средние сервисы**: растущие SaaS-продукты, ведомственные системы, региональные сайты электронной коммерции, бэкэнды мобильных приложений, API для B2B-интеграции

- **Крупные сервисы**: устоявшиеся корпоративные продукты, национальные платформы электронной коммерции, крупные мобильные приложения, многопользовательские SaaS-платформы, платежные системы

- **Глобальный масштаб**: платформы социальных сетей, поисковые системы, провайдеры CDN, услуги облачной инфраструктуры, глобальные платформы потокового вещания (Netflix, YouTube)

Datadog обеспечивает комплексный сбор и визуализацию метрик для облачных сред, предлагая автоматическое обнаружение сервисов, настраиваемые панели мониторинга и интеграцию инфраструктуры. Поставщики облачных услуг предлагают управляемые решения, включая AWS CloudWatch, Google Cloud Monitoring и Azure Monitor.
Инструментирование должно происходить на уровне бизнес-логики наряду с мониторингом инфраструктуры. Отслеживание регистраций пользователей, успешных транзакций и использования функций обеспечивает немедленный контекст бизнес-воздействия при возникновении технических проблем.

### Журналы: описания приложений

Журналы предоставляют описания поведения приложений. В то время как метрики указывают, что происходит, журналы объясняют, почему это происходит, создавая цепочку событий, ведущую от «что-то не так» до «вот что именно пошло не так».

Основная проблема журналов заключается не в объеме собираемых данных, а в их полезности во время инцидентов. Команды часто генерируют большие объемы журналов, но затрудняются найти нужную информацию, когда она нужна. Эту проблему решает структурированное ведение журналов с единым форматом и понятным контекстом.

Структурированные журналы, обычно в формате JSON, облегчают поиск и анализ. В отличие от текста в свободной форме, требующего интерпретации человеком, структурированные журналы создают данные, которые могут использовать как люди, так и машины. Включите идентификаторы корреляции, идентификаторы пользователей, идентификаторы запросов и контекстную информацию, позволяющую отслеживать сложные рабочие процессы.

Уровни журналов требуют тщательного рассмотрения. ERROR указывает на сбои в системе, требующие немедленного внимания. WARN указывает на необычные условия, требующие последующего расследования. INFO фиксирует важные события приложения, а DEBUG предоставляет подробную информацию об исполнении для устранения неполадок.

Традиционное управление журналами требовало сложной настройки нескольких инструментов, но современные платформы, такие как Datadog, предлагают интегрированную observability с эффективным управлением журналами, поиском в реальном времени и корреляцией с метриками и трассировками. Поставщики облачных услуг предлагают управляемые решения, включая AWS CloudWatch Logs, Google Cloud Logging и Azure Monitor Logs.

Критические шаблоны ведения журналов включают в себя фиксацию входа и выхода важных бизнес-операций с входными данными и результатами. В случае сбоев это обеспечивает полный контекст обработанных данных и местоположения сбоев.

### Трассировки: отслеживание пути запроса

В средах микросервисов запросы одного пользователя могут затрагивать десятки сервисов. Традиционные журналы и метрики могут определить, что сервис A работает медленно, но не могут легко определить, что медленная работа сервиса A является результатом таймаутов сервиса C, которые возникают из-за перегрузки базы данных сервиса F.

Распределенное отслеживание решает эту проблему, отслеживая полный путь запроса через системы. Каждый сервис добавляет интервалы к трассировкам, создавая временную шкалу событий и продолжительность шагов, что функционирует как GPS-отслеживание запросов.

Распределенное отслеживание позволяет установить прямую связь между проблемами производительности и их первопричинами. При расследовании медленных запросов происходит немедленное выявление сервисов или зависимостей, в наибольшей степени влияющих на задержки, без необходимости ручной корреляции.

Реализации варьируются от примитивного регистрации корреляционных идентификаторов до сложных решений, таких как Datadog APM, обеспечивающих автоматическую инструментацию и корреляцию трассировок между сервисами.

OpenTelemetry стал стандартом распределенного отслеживания, предоставляя независимые от поставщиков API и SDK с широкой поддержкой решений.

Для успешного трассирования необходим выборочный охват. Трассирование всего оказывается дорогостоящим и шумным. Сосредоточьтесь на критических пользовательских путях и границах сервисов: трассируйте аутентификацию пользователей, обработку платежей и запись данных, потенциально пропуская внутренние запросы к кэшу, если только не выполняете отладку проблем с производительностью.

### Оповещения: системы раннего предупреждения

Оповещения связывают observability и действия, соединяя «Я знаю, что что-то не так» с «Я что-то делаю, чтобы это исправить». Плохие оповещения хуже, чем их отсутствие.

Усталость от оповещений возникает, когда команды получают слишком много ложных срабатываний, что приводит к игнорированию оповещений и пропуску критических проблем. Решением является улучшение качества и релевантности оповещений, а не простое сокращение их количества.

Оповещайте о симптомах, которые испытывают пользователи, а не о внутренних состояниях системы, которые могут не иметь значения. Переполненные диски на репликах базы данных могут не повлиять на пользователей с автоматической отработкой отказа, но всплески частоты ошибок API определенно повлияют.

Datadog предоставляет комплексные оповещения с интеллектуальными функциями, включая корреляцию оповещений, обнаружение аномалий и автоматическую группировку для уменьшения шума. Он поддерживает оповещения с несколькими условиями, политики эскалации и интеграцию с каналами уведомлений, такими как Slack, электронная почта и конечные точки веб-хуков.

## Инженерия надежности сайта

Инженерия надежности сайта (SRE), подход Google к управлению системами в больших масштабах, предоставляет рамки для систематического, а не реактивного подхода к обеспечению надежности. В своей основе SRE балансирует надежность и скорость внедрения новых функций посредством измерения и автоматизации.

### Основные концепции SRE

**Показатели уровня обслуживания (SLI)** предоставляют количественные меры поведения сервиса, значимого для пользователя, обычно выраженные в виде коэффициентов: успешные запросы/общее количество запросов для доступности или запросы, выполненные в пределах порогового значения/общее количество запросов для задержки. Ключевые SLI веб-приложений включают задержку запросов и частоту ошибок. К SLI, относящимся к конвейеру данных, относятся задержка обработки, пропускная способность и точность данных. Основной принцип заключается в выборе SLI, непосредственно отражающих пользовательский опыт, а не внутренние метрики системы.

**Цели уровня обслуживания (SLO)** определяют целевые значения SLI за определенные периоды времени. SLO должны быть конкретными, измеримыми, достижимыми и ограниченными по времени. Примеры: «Наш API будет отвечать на 95 % запросов в течение 200 мс в течение любого 30-дневного скользящего окна» или «99,9 % запросов пользователей будут получать успешные ответы (коды статуса 2xx или 3xx) в течение каждого календарного месяца». SLO должны балансировать между амбициозностью (стремлением к повышению надежности) и достижимостью (предотвращением постоянных сбоев).

**Бюджеты ошибок** количественно определяют допустимый уровень ненадежности, рассчитываемый как (1 - SLO). Если SLO доступности составляет 99,9%, бюджет ошибок равен 0,1%. Это переводится в конкретные допустимые значения: сервисы, обрабатывающие 1 миллион запросов в месяц с SLO 99,9%, допускают 1000 неудачных запросов в месяц. Бюджеты ошибок предоставляют конечные ресурсы, которые команды могут «тратить» на скорость реализации функций, сохраняя при этом целевые показатели надежности.

Бюджеты ошибок превращают дискуссии о надежности из субъективных дебатов в объективные решения, основанные на данных. Решения о сроках развертывания зависят от текущего потребления бюджета ошибок, а не от интуиции или неприятия риска.

### Внедрение SRE

Команды SRE обычно делят время между операционной работой (реагирование на инциденты, управление трудоемкими задачами) и инженерной работой (создание автоматизации, повышение надежности). Цель состоит в автоматизации повторяющихся операционных задач, чтобы сосредоточиться на систематическом улучшении.

**Трудоемкие задачи** — это ручная, повторяющаяся, автоматизируемая работа, не приносящая долгосрочной пользы. Команды SRE систематически измеряют и минимизируют трудоемкие задачи, создавая стимулы для лучшей автоматизации и разработки самовосстанавливающихся систем.

**Политика бюджета ошибок** определяет реакцию организации, когда потребление бюджета ошибок превышает допустимые показатели. Эта политика обычно включает в себя эскалацию действий: потребление 50 % бюджета вызывает дополнительную проверку развертывания; 75 % требует расширенного тестирования и процессов утверждения; 90 % приостанавливает разработку функций для сосредоточения внимания на повышении надежности; 100 % вводит заморозку развертывания до восстановления бюджета. Политика должна быть разработана заранее, в спокойный период, а не в ответ на инциденты, чтобы обеспечить объективное принятие решений в условиях давления.

**Постмортемы** представляют собой упражнения по безаварийному обучению, направленные на понимание причин сбоев и методов их предотвращения. Цель состоит в выявлении системных проблем, которые привели к возникновению проблем, а не в поиске виновных, а затем в устранении этих систем.

## Резюме

Практики observability и SRE преобразуют разработку и эксплуатацию распределенных систем. Четыре основные компонента — метрики, журналы, трассировки и оповещения — обеспечивают всесторонний обзор поведения системы, а такие SRE-фреймворки, как SLI, SLO и бюджеты ошибок, позволяют принимать решения по надежности на основе данных.

Для достижения успеха не требуется одновременное внедрение всех компонентов. Начните с базовых метрик и оповещений для критически важных пользовательских путей, установите SLO для ключевых сервисов и постепенно расширяйте охват. Инвестиции в инфраструктуру observability приносят дивиденды в виде более быстрого устранения инцидентов, повышения надежности системы и производительности инженеров.

По мере увеличения сложности системы эти практики становятся необходимыми для поддержания высокого уровня эксплуатации при масштабном внедрении новых функций.
